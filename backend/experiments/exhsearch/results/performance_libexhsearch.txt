Test case d1-direct-path                 resulted in actions [((1, 0), 0), (6, 2)]
Test case d1-shift-req                   resulted in actions [((1, 0), 0), (0, 3)]
Test case d2-two-shifts                  resulted in actions [((0, 1), 0), (4, 5), ((0, 5), 0), (6, 6)]
Test case d2-self-push-out               resulted in actions [((0, 1), 0), (0, 5), ((6, 5), 90), (6, 6)]
Test case d2-pushback-violation          resulted in actions [((6, 1), 0), (0, 1), ((6, 1), 180), (6, 0)]
Test case d2-long-running                resulted in actions [((0, 5), 0), (1, 4), ((1, 0), 0), (1, 6)]
Test case d3-obj-push-out                resulted in actions [((0, 1), 0), (0, 6), ((0, 1), 0), (0, 6), ((1, 6), 0), (1, 6)]
Test case d3-long-running                resulted in actions [((0, 1), 0), (4, 5), ((6, 5), 0), (3, 6), ((3, 0), 0), (2, 1)]
Test case d3-generated-8s                resulted in actions [((0, 1), 90), (1, 4), ((1, 6), 0), (1, 3), ((0, 3), 0), (6, 2)]
Test case d3-generated-23s               resulted in actions [((0, 1), 90), (6, 6), ((6, 3), 0), (6, 6), ((0, 5), 0), (0, 0)]
Test case d3-generated-33s               resulted in actions [((1, 0), 0), (1, 5), ((6, 5), 90), (0, 5), ((6, 5), 0), (5, 6)]
Test case d4-generated-86s               resulted in actions [((0, 1), 0), (4, 2), ((5, 0), 0), (6, 2), ((0, 3), 0), (7, 6), ((0, 7), 0), (7, 7)]
slightly different paths than exhaustive search python implementation, but depths are correct and tests have verified correctness of found paths.

June 20th, 2019
Test case d1-direct-path                 best of 5: 0.26ms
Test case d1-shift-req                   best of 5: 0.25ms
Test case d2-two-shifts                  best of 5: 0.91ms
Test case d2-self-push-out               best of 5: 0.38ms
Test case d2-pushback-violation          best of 5: 0.83ms
Test case d2-long-running                best of 5: 10.90ms
Test case d3-obj-push-out                best of 5: 5.94ms
Test case d3-long-running                best of 5: 11.31ms
Test case d3-generated-8s                best of 5: 10.40ms
Test case d3-generated-23s               best of 5: 15.12ms
Test case d3-generated-33s               best of 5: 45.98ms
Test case d4-generated-86s               best of 5: 1376.11ms
generally between 20 and 60 times faster. Goal: get d4-generated-86s below 1s!
I think these results were measured with a Debug build. Release build is faster by factor of about 2 to 10. See csv file for results.

d4-generated-86s removed.

September 11th, 2020
Comparison between library call and benchmark of algolibs in c++ showed that the latter is always faster.
The difference can neither be explained with only a constant factor, nor with a relative factor. It may be a combination of the two.
I am planning to profile the ctypes library call.

September 25th, 2020
I improved the bfs in libexhsearch. It now returns locations instead of node ids. This removes the need to translate the ids into locations for the next bfs.
Results see: speedup_bfs_returns_locations.png
The depth 1 and the size 7 instances have not improved, but the greater the depth and the maze size, the higher the improvement, up to a factor of 1.55.
The average improvement is 12%, and 19% for the size 13 instances.
I used valgrind on exhsearch_s13_d3_num3 and exhsearch_s11_d4_num3. 
They have about equal running times, but different speedup factors for this improvement, 1.57 and 1.13, respectively.
The examination showed that the improvement did not add any other overheads. It is rather difference in the number of shifts vs. the number of breadth-first searches which leads to the different speedups. 
